# stats/single_report.py
"""
This module is responsible for orchestrating the generation of a
comprehensive statistical report for a single Reddit user or dataset.

It performs the following key steps:
1. Loads the user's full data from a JSON file (expected format from PRAW-based reddit_utils).
2. Receives pre-fetched user 'about' data (obtained via PRAW by the caller).
3. Applies date and subreddit filters to the loaded JSON data.
4. Calls various calculation functions (from the 'calculations' module)
   on the filtered data or associated pre-filtered CSV files to compute statistics.
5. Formats the calculated statistics into a human-readable Markdown report
   using a function from the 'reporting' module.
6. Optionally saves the Markdown report to a file.
7. Optionally saves the raw calculated statistics as a JSON file.

It handles optional external dependencies gracefully, logging warnings
and skipping calculations if necessary.
"""

import json # Used for loading the initial data and saving the stats JSON
# import csv # CSV reading is handled within calculations.py now
import logging # For logging progress, warnings, and errors
import os # For path manipulation and checking file existence
import time # For timing the report generation process
from datetime import datetime, timezone # For handling timestamps and date filters
from typing import List, Optional, Dict, Any, Tuple # Type hints for better code clarity

# --- Import from sibling modules within the 'stats' package ---
# 'calculations' module contains the logic for performing the statistical calculations.
from . import calculations as calc # Use alias 'calc' for brevity when calling functions
# 'reporting' module contains the logic for formatting the calculated stats into a report string.
from .reporting import _format_report
# 'core_utils' module contains shared helper functions like timestamp handling and color codes for logging.
from .core_utils import _get_timestamp, _format_timedelta, CYAN, RESET, BOLD, YELLOW, RED, GREEN # ANSI color codes for logging output

# --- Import from modules OUTSIDE the 'stats' package ---
# These are required utility functions, expected to be provided by a module
# like 'reddit_utils.py' in the parent directory.
# get_modification_date: Used to determine the effective timestamp for filtering based on the internal dict format.
# format_timestamp: Used to format timestamps for human-readable output.
# Note: _fetch_user_about_data is NO LONGER imported or called here; the 'about_data'
#       is expected as an argument, pre-fetched by the caller using PRAW.
try:
    # Only import functions actually used within *this* module
    from reddit_utils import get_modification_date, format_timestamp
    reddit_utils_available = True
except ImportError:
    logging.critical(f"{BOLD}{RED}❌ Critical Error: Failed to import required functions (get_modification_date, format_timestamp) from reddit_utils.py! Stats generation may fail or be inaccurate.{RESET}")
    reddit_utils_available = False
    # Define dummy functions to prevent crashes if reddit_utils is missing
    def get_modification_date(entry):
        logging.error("Dummy get_modification_date called due to import failure!")
        return 0 # Indicate invalid/unfilterable date
    def format_timestamp(ts):
        logging.error("Dummy format_timestamp called due to import failure!")
        return "TIMESTAMP_ERROR" # Indicate formatting error

# --- Check Optional Dependencies needed by specific calculations ---
# (No changes needed here, these checks are independent of PRAW)
try:
    import pandas
    pandas_available_check = True
except ImportError:
    pandas_available_check = False
    logging.warning(f"{YELLOW}⚠️ Pandas library not found. Stats requiring pandas (Question Ratio, Mention Frequency) will be skipped.{RESET}")

try:
    import vaderSentiment
    vader_available_check = True
except ImportError:
    vader_available_check = False
    logging.warning(f"{YELLOW}⚠️ VADER sentiment library not found. Sentiment stats (Ratio, Arc) will be skipped.{RESET}")


# --- Data Loading & Filtering Functions ---
# (No changes needed in _load_data_from_json or _apply_filters_to_data,
# as they rely on the internal dictionary format which reddit_utils still produces)

def _load_data_from_json(json_path: Optional[str]) -> Optional[Dict[str, Any]]:
    """
    Safely loads the full user data JSON file generated by the scraping process.
    Expects data format produced by the PRAW-based reddit_utils.py.

    Args:
        json_path (Optional[str]): The path to the input JSON file containing user data.

    Returns:
        Optional[Dict[str, Any]]: The loaded data as a dictionary, or None if loading fails.
    """
    logging.debug(f"      Attempting to load stats data source: {CYAN}{json_path}{RESET}")

    # Validate input path
    if not json_path or not os.path.exists(json_path):
        logging.error(f"   {BOLD}{RED}❌ Stats generation failed: JSON file not found or path invalid: {CYAN}{json_path}{RESET}{RESET}")
        return None

    # Attempt to load the JSON file
    try:
        with open(json_path, "r", encoding="utf-8") as f:
            data = json.load(f)

        # Basic validation: ensure the loaded data is a dictionary
        if not isinstance(data, dict):
            raise ValueError("JSON root is not a dictionary")

        # Ensure top-level keys for posts ('t3') and comments ('t1') exist
        # as dictionaries, even if they are empty in the source JSON.
        if not isinstance(data.get("t1"), dict): data["t1"] = {}
        if not isinstance(data.get("t3"), dict): data["t3"] = {}

        logging.debug(f"      ✅ JSON data loaded successfully for stats ({len(data.get('t1',{}))} comments, {len(data.get('t3',{}))} posts).")
        return data

    except (json.JSONDecodeError, ValueError) as e:
        logging.error(f"   {BOLD}{RED}❌ Stats generation failed: Error parsing JSON file {CYAN}{json_path}{RESET}: {e}{RESET}")
        return None
    except Exception as e:
        logging.error(f"   {BOLD}{RED}❌ Stats generation failed: Unexpected error reading JSON file {CYAN}{json_path}{RESET}: {e}{RESET}", exc_info=True)
        return None


def _apply_filters_to_data(
    data: Dict[str, Any],
    date_filter: Tuple[float, float],
    focus_subreddits: Optional[List[str]],
    ignore_subreddits: Optional[List[str]]
) -> Dict[str, Any]:
    """
    Filters the loaded dictionary data based on date range and subreddit lists.
    Relies on get_modification_date from reddit_utils working on the loaded data structure.

    Args:
        data (Dict[str, Any]): The dictionary containing loaded Reddit data.
        date_filter (Tuple[float, float]): A tuple (start_timestamp, end_timestamp).
        focus_subreddits (Optional[List[str]]): If not None, only keep items in these subs.
        ignore_subreddits (Optional[List[str]]): If not None, ignore items in these subs.

    Returns:
        Dict[str, Any]: A new dictionary containing only the items that passed all filters.
    """
    if not data:
        logging.debug("      No data provided to filter. Returning empty filtered data.")
        return {"t1": {}, "t3": {}}

    start_ts, end_ts = date_filter
    date_filter_active = start_ts > 0 or end_ts != float('inf')
    focus_filter_active = focus_subreddits is not None and len(focus_subreddits) > 0
    ignore_filter_active = ignore_subreddits is not None and len(ignore_subreddits) > 0
    any_filter_active = date_filter_active or focus_filter_active or ignore_filter_active

    if not any_filter_active:
        logging.debug("      No filters applied to loaded JSON data.");
        return data

    logging.debug("      Applying filters to loaded JSON data...")
    filter_log_parts = []
    if date_filter_active:
        start_str = datetime.fromtimestamp(start_ts, timezone.utc).strftime('%Y-%m-%d') if start_ts > 0 else 'Beginning'
        end_str = datetime.fromtimestamp(end_ts - 1, timezone.utc).strftime('%Y-%m-%d') if end_ts != float('inf') else 'End'
        filter_log_parts.append(f"Date: {start_str} to {end_str} (based on modification time)")
    if focus_filter_active:
        filter_log_parts.append(f"Focus Subs: {focus_subreddits}")
    if ignore_filter_active:
        filter_log_parts.append(f"Ignore Subs: {ignore_subreddits}")

    logging.info(f"      Applying JSON Filters: {'; '.join(filter_log_parts)}")

    focus_lower_set = {sub.lower() for sub in focus_subreddits} if focus_filter_active else None
    ignore_lower_set = {sub.lower() for sub in ignore_subreddits} if ignore_filter_active else None

    filtered_data = {"t1": {}, "t3": {}};
    items_kept = 0;
    items_filtered_date = 0;
    items_filtered_sub = 0;
    items_error = 0;

    for kind in ["t3", "t1"]:
        for item_id, item in data.get(kind, {}).items():
            item_data = item.get("data", {})
            if not item_data:
                items_error += 1;
                logging.debug(f"         Skipping item {item_id}: Missing 'data' field.")
                continue

            # --- Date Filtering Logic ---
            if date_filter_active:
                if not reddit_utils_available:
                    logging.error("   ❌ Cannot filter by date: reddit_utils (get_modification_date) not available (checked once). Item will pass date filter.")
                    # Pass the item through date filter if function is missing
                else:
                    try:
                        ts_mod = get_modification_date(item)
                        if ts_mod == 0:
                             items_error += 1;
                             logging.debug(f"         Skipping item {item_id} for date filter: Invalid/Zero timestamp.")
                             continue
                        if not (start_ts <= ts_mod < end_ts):
                            items_filtered_date += 1;
                            continue
                    except Exception as e:
                        logging.warning(f"      ⚠️ Error getting modification date for {kind} {item_id}: {e}. Filtering out item due to error.")
                        items_error += 1;
                        continue

            # --- Subreddit Filtering Logic ---
            if focus_filter_active or ignore_filter_active:
                try:
                    subreddit = item_data.get("subreddit")
                    if not subreddit or not isinstance(subreddit, str):
                        items_filtered_sub += 1;
                        continue

                    item_subreddit_lower = subreddit.lower()
                    focus_match = (focus_lower_set is None) or (item_subreddit_lower in focus_lower_set)
                    ignore_match = (ignore_lower_set is None) or (item_subreddit_lower not in ignore_lower_set)

                    if not (focus_match and ignore_match):
                        items_filtered_sub += 1;
                        continue
                except Exception as e:
                    logging.warning(f"      ⚠️ Error accessing subreddit for {kind} {item_id}: {e}. Filtering out item due to error.")
                    items_error += 1;
                    continue

            filtered_data[kind][item_id] = item
            items_kept += 1

    total_processed = len(data.get("t1",{})) + len(data.get("t3",{}))
    total_filtered = items_filtered_date + items_filtered_sub + items_error
    logging.info(f"      📊 JSON Filters Applied: {items_kept} items kept (out of {total_processed} total).")
    if total_filtered > 0:
         filter_details = []
         if items_filtered_date > 0: filter_details.append(f"{items_filtered_date} by date")
         if items_filtered_sub > 0: filter_details.append(f"{items_filtered_sub} by subreddit rules")
         if items_error > 0: filter_details.append(f"{items_error} due to errors")
         logging.info(f"         (Filtered Out Breakdown: {', '.join(filter_details)})")

    if items_kept == 0 and total_filtered > 0:
         logging.warning(f"      {YELLOW}⚠️ All items were filtered out by the specified filters or due to errors.{RESET}")

    return filtered_data


# --- Main Stats Generation Function ---
def generate_stats_report(
    json_path: Optional[str],
    about_data: Optional[Dict[str, Any]], # Expects pre-fetched data (using PRAW by caller)
    posts_csv_path: Optional[str], # Expects path to pre-filtered CSV
    comments_csv_path: Optional[str], # Expects path to pre-filtered CSV
    username: str,
    output_path: Optional[str],
    stats_json_path: Optional[str],
    date_filter: Tuple[float, float] = (0, float('inf')),
    focus_subreddits: Optional[List[str]] = None,
    ignore_subreddits: Optional[List[str]] = None,
    top_n_words: int = 50,
    top_n_items: int = 5,
    ngram_n_values: List[int] = [2, 3],
    ngram_top_k: int = 20,
    mention_top_n: int = 20,
    sentiment_arc_window: str = 'monthly',
    write_md_report: bool = True,
    write_json_report: bool = True
) -> Tuple[bool, Optional[Dict[str, Any]]]:
    """
    Orchestrates the process of loading, filtering, calculating, formatting,
    and saving a single user's Reddit statistics report.

    Args:
        json_path (Optional[str]): Path to the input JSON file with raw user data
                                   (format from PRAW-based reddit_utils expected).
        about_data (Optional[Dict[str, Any]]): User's 'about' data (karma, created, etc.),
                                               PRE-FETCHED by the caller (e.g., using PRAW).
        posts_csv_path (Optional[str]): Path to the CSV file containing PRE-FILTERED post data.
        comments_csv_path (Optional[str]): Path to the CSV file containing PRE-FILTERED comment data.
        username (str): The Reddit username to generate the report for.
        output_path (Optional[str]): Path to save the Markdown report file.
        stats_json_path (Optional[str]): Path to save the raw calculated stats as JSON.
        date_filter (Tuple[float, float]): Date filter as (start_ts, end_ts).
        focus_subreddits (Optional[List[str]]): List of subreddits to focus on.
        ignore_subreddits (Optional[List[str]]): List of subreddits to ignore.
        top_n_words (int): Number of top words for frequency calculation.
        top_n_items (int): Number of top/bottom items for score stats.
        ngram_n_values (List[int]): List of N values for n-gram calculation.
        ngram_top_k (int): Number of top k n-grams to find.
        mention_top_n (int): Number of top mentioned users/subs to include.
        sentiment_arc_window (str): Time window for sentiment arc ('monthly'/'yearly').
        write_md_report (bool): Flag to control Markdown report generation.
        write_json_report (bool): Flag to control JSON stats data saving.

    Returns:
        Tuple[bool, Optional[Dict[str, Any]]]: (Success flag, Calculated stats dictionary or None).
                                               Success is True if the process completed without
                                               critical errors (like load failure or save failure
                                               if saving was requested). Skipped optional calculations
                                               do not cause failure. Returns None for stats dict
                                               only on initial JSON load failure.
    """
    start_time = time.time()
    generate_output = write_md_report or write_json_report
    filter_applied = date_filter != (0, float('inf')) or focus_subreddits is not None or ignore_subreddits is not None

    if generate_output:
        logging.info(f"   📊 Generating statistics report for /u/{BOLD}{username}{RESET}...")

    # --- Step 1: Load Data from JSON ---
    full_data = _load_data_from_json(json_path)
    if full_data is None:
        logging.error("   ❌ Report generation aborted due to critical data loading failure.")
        return False, None

    # --- Step 2: Apply Filters ---
    filtered_data = _apply_filters_to_data(
        full_data,
        date_filter=date_filter,
        focus_subreddits=focus_subreddits,
        ignore_subreddits=ignore_subreddits
    )

    # --- Check for Data After Filtering ---
    if not filtered_data.get("t1") and not filtered_data.get("t3"):
         if generate_output:
             logging.warning(f"   {YELLOW}⚠️ No data remains for /u/{username} after applying filters. Skipping stats calculation.{RESET}")
         # Return success=True, but include flags for reporting that no data was found after filtering
         return True, {"_filter_applied": filter_applied, "_no_data_after_filter": True}

    # --- Check for About Data ---
    if about_data is None and generate_output:
        # Log warning - caller is responsible for fetching about_data using PRAW
        logging.warning(f"      {YELLOW}⚠️ Pre-fetched user 'about' data not provided. Account Age/Karma stats might be incomplete.{RESET}")

    # --- Step 3: Calculate Statistics ---
    stats_results = {}
    calculation_errors = []

    try:
        if generate_output:
             logging.info("   ⚙️ Calculating statistics...")

        # --- Call calculation functions from calculations.py ---
        # (No changes needed here, assuming calculation functions correctly handle inputs)
        stats_results["basic_counts"] = calc._calculate_basic_counts(filtered_data)
        stats_results["time_range"] = calc._calculate_time_range(filtered_data)
        stats_results["subreddit_activity"] = calc._calculate_subreddit_activity(filtered_data)
        stats_results["engagement"] = calc._calculate_engagement_stats(filtered_data, about_data) # Uses pre-fetched about_data
        stats_results["post_types"] = calc._calculate_post_types(filtered_data)
        stats_results["temporal_stats"] = calc._calculate_temporal_stats(filtered_data)
        stats_results["score_stats"] = calc._calculate_score_stats(filtered_data, top_n=top_n_items)
        stats_results["award_stats"] = calc._calculate_award_stats(filtered_data)
        stats_results["flair_stats"] = calc._calculate_flair_stats(filtered_data)
        stats_results["post_engagement"] = calc._calculate_post_engagement(filtered_data)
        stats_results["editing_stats"] = calc._calculate_editing_stats(filtered_data)
        stats_results['age_activity_analysis'] = calc._calculate_age_vs_activity(about_data, stats_results.get('temporal_stats')) # Uses pre-fetched about_data
        stats_results['crosspost_stats'] = calc._calculate_crosspost_stats(filtered_data)
        stats_results['removal_deletion_stats'] = calc._calculate_removal_deletion_stats(filtered_data)
        stats_results['subreddit_diversity'] = calc._calculate_subreddit_diversity(stats_results.get('subreddit_activity'))
        stats_results['activity_burstiness'] = calc._calculate_activity_burstiness(filtered_data)

        # Calculations using pre-filtered CSV paths
        stats_results["text_stats"] = calc._calculate_text_stats(posts_csv_path, comments_csv_path)
        stats_results["word_frequency"] = calc._calculate_word_frequency(posts_csv_path, comments_csv_path, top_n=top_n_words)
        stats_results['ngram_frequency'] = calc._calculate_ngram_frequency(posts_csv_path, comments_csv_path, n_values=ngram_n_values, top_k=ngram_top_k)
        stats_results["sentiment_ratio"] = calc._calculate_sentiment_ratio(posts_csv_path, comments_csv_path)
        stats_results['reply_depth'] = calc._calculate_reply_depth(comments_csv_path)
        stats_results['sentiment_arc'] = calc._calculate_sentiment_arc(filtered_data, time_window=sentiment_arc_window)
        stats_results['question_ratio_stats'] = calc._calculate_question_ratio(posts_csv_path, comments_csv_path)
        stats_results['mention_stats'] = calc._calculate_mention_frequency(posts_csv_path, comments_csv_path, top_n=mention_top_n)
        # --- End calculation calls ---


        # --- Add Filter Info to Results for Reporting ---
        if write_md_report and filter_applied:
            start_f, end_f = date_filter
            start_str = datetime.fromtimestamp(start_f, timezone.utc).strftime('%Y-%m-%d') if start_f > 0 else None
            end_str = datetime.fromtimestamp(end_f - 1, timezone.utc).strftime('%Y-%m-%d') if end_f != float('inf') else None
            date_info_for_report = {"start": start_str, "end": end_str} if date_filter != (0, float('inf')) else {}

            stats_results["_filter_info"] = {
                **date_info_for_report,
                "focus_subreddits": focus_subreddits,
                "ignore_subreddits": ignore_subreddits
            }
        stats_results["_filter_applied"] = filter_applied

        if generate_output:
            logging.info(f"   {GREEN}✅ All statistics calculated.{RESET}")

    except Exception as e:
        logging.error(f"   {RED}❌ Error during statistics calculation phase: {e}{RESET}", exc_info=True)
        calculation_errors.append(f"Calculation Error: {e}")

    # --- Step 4: Format Markdown Report ---
    report_content = None
    formatting_success = False

    if write_md_report:
        logging.info("   ✍️ Formatting statistics report...")
        try:
            # Pass stats dict and filter lists to formatter
            report_content = _format_report(
                stats_data=stats_results,
                username=username,
                focus_subreddits=focus_subreddits,
                ignore_subreddits=ignore_subreddits
            )
            formatting_success = True
            logging.debug("      Report formatting complete.")
        except Exception as e:
            logging.error(f"   {RED}❌ Error during report formatting: {e}{RESET}", exc_info=True)
            calculation_errors.append(f"Report Formatting Error: {e}")

    # --- Step 5: Save Markdown Report ---
    md_saved = False
    if write_md_report and formatting_success and report_content and output_path:
        logging.info(f"   💾 Saving statistics report to {CYAN}{output_path}{RESET}...")
        try:
            os.makedirs(os.path.dirname(output_path) or '.', exist_ok=True)
            with open(output_path, "w", encoding="utf-8") as f:
                f.write(report_content)
            md_saved = True
            logging.info(f"   {GREEN}✅ Markdown report saved successfully.{RESET}")
        except IOError as e:
            logging.error(f"   {RED}❌ Error saving statistics report to {CYAN}{output_path}{RESET}: {e}{RESET}", exc_info=False) # Less verbose log
            calculation_errors.append(f"MD Save IO Error: {e}")
        except Exception as e:
             logging.error(f"   {RED}❌ Unexpected error saving statistics report to {CYAN}{output_path}{RESET}: {e}{RESET}", exc_info=True)
             calculation_errors.append(f"MD Save Unexpected Error: {e}")
    elif write_md_report:
         if not output_path: logging.error(f"   {RED}❌ Skipping MD report save: No output path provided.{RESET}")
         elif not formatting_success: logging.error(f"   {RED}❌ Skipping MD report save due to formatting errors.{RESET}")
         elif not report_content: logging.error(f"   {RED}❌ Skipping MD report save due to missing report content.{RESET}")


    # --- Step 6: Save JSON Stats Data ---
    json_saved = False
    if write_json_report and stats_json_path:
        logging.info(f"   💾 Saving calculated stats data to {CYAN}{stats_json_path}{RESET}...")
        # Prepare cleaned results, removing internal keys and adding errors
        clean_stats_results = {k: v for k, v in stats_results.items() if not k.startswith('_')}
        if calculation_errors:
            clean_stats_results["_calculation_errors"] = calculation_errors

        try:
            os.makedirs(os.path.dirname(stats_json_path) or '.', exist_ok=True)
            with open(stats_json_path, "w", encoding="utf-8") as f_json:
                # Use default=str to handle potential non-serializable types gracefully
                json.dump(clean_stats_results, f_json, indent=2, default=str)
            json_saved = True
            logging.info(f"   {GREEN}✅ JSON stats data saved successfully.{RESET}")
        except TypeError as e:
             logging.error(f"   {RED}❌ Error saving JSON stats data (non-serializable type?) to {CYAN}{stats_json_path}{RESET}: {e}{RESET}", exc_info=False) # Less verbose log
             calculation_errors.append(f"JSON Save Type Error: {e}")
        except IOError as e:
            logging.error(f"   {RED}❌ Error saving JSON stats data to {CYAN}{stats_json_path}{RESET}: {e}{RESET}", exc_info=False) # Less verbose log
            calculation_errors.append(f"JSON Save IO Error: {e}")
        except Exception as e:
             logging.error(f"   {RED}❌ Unexpected error saving JSON stats data to {CYAN}{stats_json_path}{RESET}: {e}{RESET}", exc_info=True)
             calculation_errors.append(f"JSON Save Unexpected Error: {e}")


    # --- Final Status and Return ---
    elapsed_time = time.time() - start_time
    if generate_output:
        logging.info(f"   ⏱️ Statistics generation finished in {elapsed_time:.2f}s.")

    # Success is defined as: no calculation errors AND any requested save operation succeeded.
    # Load failures return earlier.
    final_success = not calculation_errors
    if write_md_report and output_path and not md_saved:
        final_success = False
        logging.error(f"   {BOLD}{RED}❌ Single report generation failed: Markdown report could not be saved.{RESET}")
    if write_json_report and stats_json_path and not json_saved:
        final_success = False
        logging.error(f"   {BOLD}{RED}❌ Single report generation failed: JSON stats data could not be saved.{RESET}")

    # Return the final success flag and the calculated stats results dictionary
    return final_success, stats_results