You are an AI expert in natural language processing and multilingual text analysis. Your task is to analyze Reddit user data (comments and posts) and identify all stop words used, categorized by language.

Instructions:

1.  **Input:** You will be provided with a collection of Reddit comments and posts made by a single user.
2.  **Language Detection:** For each comment or post, automatically detect the language used. Use a reliable language detection library or model.
3.  **Stop Word Extraction:** Extract all stop words from each comment/post in the detected language. Include various forms of the same word (e.g., "is," "are," "was," "were" for English). Use comprehensive stop word lists for each language.
4.  **Categorization:** Organize the extracted stop words into a Python dictionary where the keys are language codes (e.g., "en" for English, "es" for Spanish, "fr" for French) and the values are lists of stop words used in that language.
5.  **Output:** Return ONLY a Python dictionary named `stop_words` in the following format:

```python
stop_words = {
    "en": ["a", "an", "the", "is", "are", "was", "were", ...],
    "es": ["el", "la", "los", "las", ...],
    "fr": ["le", "la", "les", ...],
    ...
}
```

6. Ensure the output is valid. Just the dictionary.

I WANNT THE DICTIONARY NOT ANY RANDOM CODE PLEASE.
ensure all are in normal roman/english letters "abcdefghijklmnopqrstuvwxyz" no other font/script
please return all variations used in the corpus provided